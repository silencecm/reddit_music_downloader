import json
import subprocess
import urllib2
import time
import datetime

# Used with resolve_redirects method. Sometimes urllib2.urlopen fails "Code 429: Too many requests.
redirect_timeout = 20

today = datetime.date.today()
formatted_date = str(today.day) + "_" + str(today.month) + "_" + str(today.year)

def resolve_redirects(request):
    try:
        return urllib2.urlopen(request)
    except urllib2.HTTPError, e:
        if e.code == 429:
             print "[WARNING]: UrlLib2 Code 429: TOO MANY REQUESTS. Sleeping for " + str(redirect_timeout) + " seconds."
             time.sleep(redirect_timeout)
             return resolve_redirects(request)
        raise

# Loop over defined subreddits (sources/subreddits)
with open('sources/subreddits') as subreddits:
    for subreddit in subreddits:
        # Ignore comments (lines that start with #) and empty lines
        if (subreddit[0] == "#" or subreddit == "\n"):
            continue

        # Build a url for each subreddit found
        subreddit_json_url = "https://www.reddit.com/r/" + subreddit.rstrip() + "/new.json?sort=new"
        print "Processing json for: " + subreddit.rstrip() + " using URL: " + subreddit_json_url

        # Process the request, parse the json and fetch each source found
        request = urllib2.Request(subreddit_json_url)
        response = resolve_redirects(request)
        json_object = json.load(response)

        for children in json_object['data']['children']:
            media = children['data']
            url = media['url']

            # Check if the url has been downloaded before
            with open('sources/downloaded', 'r') as downloaded:
                if url in downloaded.read():
                    print "URL found in downloaded. Skipping."
                else:
                    if "youtube" in url:
                        print "Processing youtube download of " + url + " to fetched_media/" + formatted_date + "/" + subreddit.strip()
                        bashCommand = 'youtube-dl -o fetched_media/' + formatted_date + "/" + subreddit.strip() + "/" + '/%(title)s-%(id)s.%(ext)s --extract-audio --audio-format mp3 ' + url
                        process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)
                        output, error = process.communicate()
                        with open('sources/downloaded', 'a') as dl:
                            print "Appending URL to downloaded file."
                            dl.write(url + "\n")